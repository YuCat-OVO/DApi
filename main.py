import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional
from typing import Union

import urllib3
from tqdm import tqdm
from urllib3.exceptions import InsecureRequestWarning

from config import (
    URL_PROCESSING_MAX_PROCESSES,
    SHOW_SSL_PROGRESS_BAR,
    TEST_DATA,
    REPLY_RULE,
    SAVE_PROCESSED_DATA,
)
from logging_utils import setup_logger
from network_utils import check_endpoint
from url_utils import generate_urls

setup_logger()


# Suppress InsecureRequestWarning globally
urllib3.disable_warnings(InsecureRequestWarning)


def categorize_result(
    url: str,
    response: Union[str, dict[str, Union[str, float]]],
    categorized_results: dict[str, Union[dict[str, float], list[str]]],
) -> None:
    """
    æ ¹æ®ç»“æœåˆ†ç±» URLã€‚

    Args:
        response: Union[str, dict[str, Union[str, float]]]: æ£€æŸ¥ç»“æœã€‚
        url (str): å½“å‰ URLã€‚
        categorized_results (dict): åˆ†ç±»ç»“æœå­—å…¸ã€‚
    """
    status = response.get("status", "failed")

    if status == "success":
        protocol_cate = (
            "available_https_endpoints"
            if url.startswith("https://")
            else "available_http_endpoints"
        )
        categorized_results[protocol_cate][url] = response.get("latency")
    elif status == "429":
        categorized_results["rate_limited"][url] = response.get("latency")
    elif status == "50x":
        categorized_results["service_unavailable"][url] = response.get("latency")
    elif status == "timeout":
        categorized_results["timeout_or_unreachable"].append(url)
    elif status == "401":
        categorized_results["unauthorized_urls"].append(url)
    else:
        categorized_results["failed_urls"].append(url)


def process_urls_with_thread_pool(
    urls: list[str],
    categorized_results: dict[str, Union[dict[str, float], list[str]]],
    max_workers: int = URL_PROCESSING_MAX_PROCESSES,
    show_progress: bool = SHOW_SSL_PROGRESS_BAR,
) -> None:
    """
    Process URL tasks using a thread pool.

    Args:
        urls (list[str]): List of URLs to check.
        categorized_results (Optional[dict]): Dictionary to store categorized results.
        max_workers (int): Maximum number of worker threads.
        show_progress (bool): Whether to display a progress bar.
    """
    # Initialize the ThreadPoolExecutor
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []

        # åˆå§‹åŒ–è¿›åº¦æ¡
        progress_bar = (
            tqdm(total=len(urls), desc="Checking APIs") if show_progress else None
        )

        for url in urls:
            futures.append(executor.submit(check_endpoint, url, TEST_DATA, REPLY_RULE))

        for future in as_completed(futures):
            result = future.result()
            url, response = result
            if result:
                categorize_result(url, response, categorized_results)
            if progress_bar:
                progress_bar.update(1)

        # å…³é—­è¿›åº¦æ¡
        if progress_bar:
            progress_bar.close()


def display_results(
    categorized_results: dict[str, Union[dict[str, float], list[str]]],
    show_list: bool = False,
    sort_results: bool = True,
) -> None:
    """
    æ˜¾ç¤ºåˆ†ç±»ç»“æœã€‚

    Args:
        categorized_results (dict): åŒ…å«æ‰€æœ‰åˆ†ç±»ç»“æœçš„å­—å…¸ã€‚
        show_list (bool): æ˜¯å¦è¾“å‡ºçº¯å‡€çš„ URL åˆ—è¡¨ï¼ˆæ— å»¶è¿Ÿå’Œ Emojiï¼‰ã€‚
        sort_results (bool): æ˜¯å¦æŒ‰å»¶è¿Ÿæ’åºï¼Œé»˜è®¤æŒ‰å»¶è¿Ÿæ’åºï¼ˆä»…å¯¹ "available_endpoints" çš„æ•°æ®ç”Ÿæ•ˆï¼‰ã€‚
    """

    def print_urls(title: str, url_dict: dict[str, float], emoji: str) -> None:
        """æ‰“å°åˆ†ç±» URL åˆ—è¡¨ï¼ˆæ”¯æŒæ’åºå’Œå»¶è¿Ÿæ˜¾ç¤ºï¼‰ã€‚"""
        print(f"\n{emoji} {title}:")
        urls = list(url_dict.keys())
        if sort_results:
            urls = sorted(urls, key=lambda this_url: url_dict[this_url])
        for url in urls:
            latency = url_dict[url]
            latency_display = (
                "Timeout" if latency == float("inf") else f"{latency:.2f} ms"
            )
            print(f"{emoji} {url} (Latency: {latency_display})")

    # æ‰“å° HTTPS å’Œ HTTP çš„ç«¯ç‚¹
    print_urls(
        "HTTPS Endpoints",
        categorized_results.get("available_https_endpoints"),
        "\U0001F512",  # ğŸ”
    )
    print_urls(
        "HTTP Endpoints",
        categorized_results.get("available_http_endpoints"),
        "\U0001F310",  # ğŸŒ
    )

    # æ‰“å°å—é™åˆ¶çš„ URL
    print_urls(
        "Rate Limited URLs",
        categorized_results.get("rate_limited"),
        "\U0001F6AB",  # ğŸš«
    )

    # æ‰“å°50x URL
    print_urls(
        "Service Unavailable URLs",
        categorized_results.get("service_unavailable"),
        "\U0001F6AB",  # ğŸš«
    )

    # åˆ†ç±»æ±‡æ€»
    if not show_list:
        print("\n\U0001F4CA Summary of Results:")  # ğŸ“Š
        for category, data in categorized_results.items():
            if isinstance(data, dict):  # å¤„ç†å­—å…¸ç±»å‹çš„æ•°æ®
                print(f"  - {category.replace('_', ' ').title()}: {len(data)} URLs")
            elif isinstance(data, list):  # å¤„ç†åˆ—è¡¨ç±»å‹çš„æ•°æ®
                print(f"  - {category.replace('_', ' ').title()}: {len(data)} URLs")


def main():
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡Œ URL æ£€æŸ¥å’Œç»“æœä¿å­˜å·¥ä½œã€‚

    """
    # åŠ è½½ URL å’Œåˆå§‹æ•°æ®
    urls = generate_urls()
    if not urls:
        logging.error("No URLs to check. Exiting.")
        return

    if SAVE_PROCESSED_DATA:
        with open("processed_urls.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(urls))

    # åˆå§‹åŒ–åˆ†ç±»ç»“æœå­—å…¸
    categorized_results = {
        "available_https_endpoints": {},
        "available_http_endpoints": {},
        "rate_limited": {},
        "service_unavailable": {},
        "timeout_or_unreachable": [],
        "unauthorized_urls": [],
        "failed_urls": [],
    }

    # ä½¿ç”¨çº¿ç¨‹æ± æ£€æŸ¥ URL
    process_urls_with_thread_pool(urls, categorized_results)

    # æ‰“å°åˆ†ç±»ç»“æœ
    display_results(categorized_results)

    if SAVE_PROCESSED_DATA:
        # å¯¹ HTTPS ç«¯ç‚¹è¿›è¡Œæ’åºåä¿å­˜
        https_sorted = sorted(
            categorized_results.get("available_https_endpoints", {}).items(),
            key=lambda item: item[1],  # æŒ‰å»¶è¿Ÿå€¼æ’åº
        )
        with open("https_urls.txt", "w", encoding="utf-8") as f:
            for url, latency in https_sorted:
                f.write(f"{url} (Latency: {latency})\n")

        # å¯¹ HTTP ç«¯ç‚¹è¿›è¡Œæ’åºåä¿å­˜
        http_sorted = sorted(
            categorized_results.get("available_http_endpoints", {}).items(),
            key=lambda item: item[1],  # æŒ‰å»¶è¿Ÿå€¼æ’åº
        )
        with open("http_urls.txt", "w", encoding="utf-8") as f:
            for url, latency in http_sorted:
                f.write(f"{url} (Latency: {latency})\n")

        rate_limit = sorted(categorized_results.get("rat"))


if __name__ == "__main__":
    main()
